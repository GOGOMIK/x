{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9981f4b0",
      "metadata": {
        "id": "9981f4b0"
      },
      "source": [
        "# Tutorial Notebook 10: Finetuning for Perturbation Response Prediction\n",
        "\n",
        "In this tutorial, we will demonstrate how to finetune a Cell2Sentence (C2S) model for perturbation response prediction tasks. This is a critical task in single-cell analysis, where the goal is to predict how a cell's gene expression profile changes in response to a specific perturbation (e.g., a genetic knockout or a drug treatment).\n",
        "\n",
        "We will treat this as a \"translation\" task in natural language: translating a cell (in cell sentence format) from its basal (control) state to its perturbed state, conditioned on the perturbation applied.\n",
        "\n",
        "At a high level, we will:\n",
        "1. Load a public single-cell perturbation dataset.\n",
        "2. Write a custom prompt template for perturbation prediction.\n",
        "3. Subclass the `PromptFormatter` class to create pairs of control and perturbed cells.\n",
        "4. Finetune a pretrained C2S-Scale model on this new task.\n",
        "5. Generate a prediction with our new finetuned model to see it in action."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "139d5b0b",
      "metadata": {
        "id": "139d5b0b"
      },
      "source": [
        "First, let's import the necessary libraries. We'll need standard data science libraries, single-cell analysis tools, and modules from the `cell2sentence` and `transformers` packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0bf13c5",
      "metadata": {
        "id": "f0bf13c5"
      },
      "outputs": [],
      "source": [
        "# Python built-in libraries\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
        "\n",
        "import pickle\n",
        "import random\n",
        "from datetime import datetime\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Third-party libraries\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import TrainingArguments, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Single-cell libraries\n",
        "import anndata\n",
        "import scanpy as sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb07037d",
      "metadata": {
        "id": "cb07037d"
      },
      "outputs": [],
      "source": [
        "# Cell2Sentence imports\n",
        "import cell2sentence as cs\n",
        "from cell2sentence.prompt_formatter import get_cell_sentence_str, PromptFormatter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27c84498"
      },
      "source": [
        "Let's install all the required libraries for this notebook."
      ],
      "id": "27c84498"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eec0ee64"
      },
      "source": [
        "!pip install anndata scanpy datasets transformers tqdm cell2sentence torch"
      ],
      "id": "eec0ee64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ce734c",
      "metadata": {
        "id": "81ce734c"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f6047f8",
      "metadata": {
        "id": "0f6047f8"
      },
      "source": [
        "# Load Perturbation Data\n",
        "\n",
        "For this tutorial, you will need a single-cell dataset that includes both control and perturbed cells. The data should be in an `AnnData` object. Crucially, your `.obs` dataframe must contain:\n",
        "- A column that distinguishes control cells from perturbed cells, e.g., `adata.obs['condition']`\n",
        "    - Values can be something like 'control' or 'non-targeting' for control cells, and 'perturbed' or the perturbation name for the perturbed cells\n",
        "\n",
        "For this example, we use a public genetic perturbation dataset of Jurkat cells (Nadig et al., 2025). To use your own dataset, replace `DATA_PATH` with the path to your preprocessed data file.\n",
        "- Paper: https://www.nature.com/articles/s41588-025-02169-3\n",
        "\n",
        "<font color='red'>Ensure your data is preprocessed and normalized (e.g., using log1p transformation) before proceeding.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52754a57",
      "metadata": {
        "id": "52754a57"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Replace this with the actual path to your dataset, if using a custom dataset\n",
        "DATA_PATH = \"/content/drive/MyDrive/Virtual_Cell_Challenge/vcc_data/adata_Training.h5ad\"\n",
        "adata = anndata.read_h5ad(DATA_PATH)\n",
        "adata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dac5016b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "dac5016b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPFL7h6yOkWG"
      },
      "id": "NPFL7h6yOkWG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590a4a9f",
      "metadata": {
        "id": "590a4a9f"
      },
      "outputs": [],
      "source": [
        "adata.obs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07fcedb",
      "metadata": {
        "id": "e07fcedb"
      },
      "outputs": [],
      "source": [
        "target_gene_counter = Counter(adata.obs['target_gene'])\n",
        "print(len(target_gene_counter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4e3458",
      "metadata": {
        "id": "ab4e3458"
      },
      "outputs": [],
      "source": [
        "target_gene_counter.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afec3e85",
      "metadata": {
        "id": "afec3e85"
      },
      "source": [
        "This data contains both control cells (non-targeting) as well as cells under different genetic knockouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ebcf86",
      "metadata": {
        "id": "38ebcf86"
      },
      "outputs": [],
      "source": [
        "adata.var.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc318b3f",
      "metadata": {
        "id": "cc318b3f"
      },
      "outputs": [],
      "source": [
        "adata.X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6239a8bc",
      "metadata": {
        "id": "6239a8bc"
      },
      "outputs": [],
      "source": [
        "# View a few nonzero values\n",
        "adata.X.data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4b95d8",
      "metadata": {
        "id": "0e4b95d8"
      },
      "outputs": [],
      "source": [
        "adata.X.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005cef4b",
      "metadata": {
        "id": "005cef4b"
      },
      "source": [
        "The expression is already preprocessed and log1p transformed. Typically, a log1p transform with base=10 would be used for Cell2Sentence training if we wish to convert generated cell sentences back to expression vectors, since log base=10 gives a better linear relationship between log rank and log expression in many single-cell datasets.\n",
        "\n",
        "For this tutorial, we will use this processed data as is, to train our model to generate target cell sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c99514",
      "metadata": {
        "id": "a1c99514"
      },
      "source": [
        "# Cell2Sentence Conversion\n",
        "\n",
        "Now, we will convert the gene expression data in our `AnnData` object into cell sentences. This process creates a Hugging Face Arrow dataset, which is used in our LLM training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ae0bdb",
      "metadata": {
        "id": "e0ae0bdb"
      },
      "outputs": [],
      "source": [
        "# We'll keep all relevant columns for our new task\n",
        "adata_obs_cols_to_keep = adata.obs.columns.tolist()\n",
        "adata_obs_cols_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e60261",
      "metadata": {
        "id": "91e60261"
      },
      "outputs": [],
      "source": [
        "# Create Arrow dataset and vocabulary\n",
        "arrow_ds, vocabulary = cs.CSData.adata_to_arrow(\n",
        "    adata=adata,\n",
        "    random_state=SEED,\n",
        "    sentence_delimiter=' ',\n",
        "    label_col_names=adata_obs_cols_to_keep\n",
        ")\n",
        "arrow_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3efc581c",
      "metadata": {
        "id": "3efc581c"
      },
      "source": [
        "# Custom Prompt Formatting for Perturbation Prediction\n",
        "\n",
        "This is the core of our tutorial. For this dataset, we have a single large pool of control cells (labeled 'non-targeting') and multiple groups of perturbed cells, each with a specific `target_gene`. Our goal is to create training pairs where each perturbed cell is matched with a randomly selected control cell. Note that for different perturbation applications, there may be better ways of pairing control and perturbed cells.\n",
        "\n",
        "We will define a custom prompt structure that frames our task for the LLM. The input will contain the **control cell sentence** and the **perturbation name**. The model's expected output (the response) will be the **perturbed cell sentence**.\n",
        "\n",
        "First, let's define our prompt templates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adceba43",
      "metadata": {
        "id": "adceba43"
      },
      "outputs": [],
      "source": [
        "# The input provides the control cell and the perturbation, asking for the perturbed result.\n",
        "custom_input_prompt_template = \"\"\"Given the following cell sentence of {num_genes} expressed genes representing a cell's basal state, predict the cell sentence after applying the perturbation: {perturbation_name}.\n",
        "Control cell sentence: {control_cell_sentence}.\n",
        "\n",
        "Perturbed cell sentence:\"\"\"\n",
        "\n",
        "# The answer is simply the target cell sentence.\n",
        "answer_template = \"{perturbed_cell_sentence}.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8afe106b",
      "metadata": {
        "id": "8afe106b"
      },
      "source": [
        "To apply this template, we need to create pairs of (control cell, perturbed cell) for each perturbation. We'll create a custom `PerturbationPromptFormatter` by subclassing the base `PromptFormatter`.\n",
        "\n",
        "Our custom `format_hf_ds` function will:\n",
        "1.  First, iterate through the entire dataset to create a list of all control cell indices.\n",
        "2.  Simultaneously, it will group the indices of all perturbed cells into a dictionary, with the perturbation name (`target_gene`) as the key.\n",
        "3.  Then, it will iterate through each perturbation group and, for every perturbed cell, randomly select a control cell from the global pool to form a pair.\n",
        "4.  Finally, it will format these pairs into the input prompts and expected responses for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fdc5ba",
      "metadata": {
        "id": "84fdc5ba"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class PerturbationPromptFormatter(PromptFormatter):\n",
        "    def __init__(self,\n",
        "        task_name,\n",
        "        input_prompt,\n",
        "        answer_template,\n",
        "        top_k_genes,\n",
        "        perturbation_col='target_gene',\n",
        "        control_label='non-targeting'\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the custom prompt formatter.\n",
        "\n",
        "        Args:\n",
        "            task_name (str): The name for this task.\n",
        "            input_prompt (str): The template for the model's input.\n",
        "            answer_template (str): The template for the model's expected response.\n",
        "            top_k_genes (int): The number of top genes to include in the cell sentence.\n",
        "            perturbation_col (str): The column name in the dataset that contains perturbation info.\n",
        "            control_label (str): The label used to identify control cells in the perturbation_col.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.task_name = task_name\n",
        "        self.input_prompt = input_prompt\n",
        "        self.answer_template = answer_template\n",
        "        self.top_k_genes = top_k_genes\n",
        "        self.perturbation_col = perturbation_col\n",
        "        self.control_label = control_label\n",
        "        assert top_k_genes > 0, \"'top_k_genes' must be an integer > 0\"\n",
        "\n",
        "    def format_hf_ds(self, hf_ds):\n",
        "        \"\"\"\n",
        "        Custom formatting function for perturbation prediction. This function creates pairs of\n",
        "        (control, perturbed) cells by sampling from a global pool of control cells.\n",
        "        \"\"\"\n",
        "        model_inputs_list = []\n",
        "        responses_list = []\n",
        "\n",
        "        # 1. Separate all cells into a global control pool and a dict of perturbed cells\n",
        "        control_indices = []\n",
        "        pert_to_indices = defaultdict(list)\n",
        "\n",
        "        print(\"Grouping cells by perturbation and identifying global controls...\")\n",
        "        for i, sample in enumerate(hf_ds):\n",
        "            if sample[self.perturbation_col] == self.control_label:\n",
        "                control_indices.append(i)\n",
        "            else:\n",
        "                pert_to_indices[sample[self.perturbation_col]].append(i)\n",
        "\n",
        "        assert len(control_indices) > 0, \"No control cells found. Cannot create pairs.\"\n",
        "        print(f\"Found {len(control_indices)} control cells.\")\n",
        "        print(f\"Found {len(pert_to_indices)} unique perturbations.\")\n",
        "\n",
        "        # 2. Create prompt-response pairs by iterating through perturbed cells\n",
        "        print(\"Creating control-perturbed pairs...\")\n",
        "        for pert_name, perturbed_indices in tqdm(pert_to_indices.items()):\n",
        "            for perturbed_idx in perturbed_indices:\n",
        "                # Pair each perturbed cell with a random control cell from the global pool\n",
        "                control_idx = random.choice(control_indices)\n",
        "\n",
        "                control_sample = hf_ds[control_idx]\n",
        "                perturbed_sample = hf_ds[perturbed_idx]\n",
        "\n",
        "                # Format control cell sentence\n",
        "                control_sentence, num_genes_str = get_cell_sentence_str(\n",
        "                    control_sample,\n",
        "                    num_genes=self.top_k_genes\n",
        "                )\n",
        "                # Format perturbed cell sentence\n",
        "                perturbed_sentence, _ = get_cell_sentence_str(\n",
        "                    perturbed_sample,\n",
        "                    num_genes=self.top_k_genes\n",
        "                )\n",
        "\n",
        "                # Format the model input string using the perturbation name\n",
        "                model_input_str = self.input_prompt.format(\n",
        "                    num_genes=num_genes_str,\n",
        "                    perturbation_name=pert_name,\n",
        "                    control_cell_sentence=control_sentence\n",
        "                )\n",
        "\n",
        "                # Format the response string\n",
        "                response_str = self.answer_template.format(\n",
        "                    perturbed_cell_sentence=perturbed_sentence\n",
        "                )\n",
        "\n",
        "                model_inputs_list.append(model_input_str)\n",
        "                responses_list.append(response_str)\n",
        "\n",
        "        # Create the final Hugging Face Dataset\n",
        "        ds_split_dict = {\n",
        "            \"sample_type\": [self.task_name] * len(model_inputs_list),\n",
        "            \"model_input\": model_inputs_list,\n",
        "            \"response\": responses_list,\n",
        "        }\n",
        "        ds = Dataset.from_dict(ds_split_dict)\n",
        "        return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e431c369",
      "metadata": {
        "id": "e431c369"
      },
      "source": [
        "Let's instantiate our custom formatter and test it on a small sample of our data to see the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68228040",
      "metadata": {
        "id": "68228040"
      },
      "outputs": [],
      "source": [
        "task_name = \"perturbation_prediction\"\n",
        "prompt_formatter = PerturbationPromptFormatter(\n",
        "    task_name=task_name,\n",
        "    input_prompt=custom_input_prompt_template,\n",
        "    answer_template=answer_template,\n",
        "    top_k_genes=200 # Using top 200 genes for this example. For real applications, ideal to use all nonzero expressed genes if possible.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51258c12",
      "metadata": {
        "id": "51258c12"
      },
      "outputs": [],
      "source": [
        "# Format the dataset\n",
        "formatted_ds = prompt_formatter.format_hf_ds(arrow_ds)\n",
        "formatted_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95e9668c",
      "metadata": {
        "id": "95e9668c"
      },
      "source": [
        "Note that if you want to do a train/test split of the data, separating out a split of control cells and holdout perturbed cells / entire perturbations can be done before formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b0f343",
      "metadata": {
        "id": "f8b0f343"
      },
      "outputs": [],
      "source": [
        "# Inspect a formatted sample\n",
        "print(\"--- Formatted Sample ---\")\n",
        "print(\"#----Model input:----#\")\n",
        "print(formatted_ds[0][\"model_input\"], \"\\n\")\n",
        "print(\"#----Response:----#\")\n",
        "print(formatted_ds[0][\"response\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c18db332",
      "metadata": {
        "id": "c18db332"
      },
      "source": [
        "Now that our custom formatter is ready, we'll wrap our original `arrow_ds` in a `CSData` object. The `finetune` function will use this object and our custom formatter to prepare the data for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ab6da2",
      "metadata": {
        "id": "28ab6da2"
      },
      "outputs": [],
      "source": [
        "# Save directory for Huggingface dataset\n",
        "c2s_save_dir = \"/home/sr2464/scratch/C2S_API_Testing/Data/perturbation_tutorial/perturbation_tutorial\"\n",
        "c2s_save_name = \"jurkat_perturbation_c2s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa776a5f",
      "metadata": {
        "id": "fa776a5f"
      },
      "outputs": [],
      "source": [
        "csdata = cs.CSData.csdata_from_arrow(\n",
        "    arrow_dataset=arrow_ds,  # Regular cell sentence dataset put here, finetune() function will repeat the formatting with the prompt formatter\n",
        "    vocabulary=vocabulary,\n",
        "    save_dir=c2s_save_dir,\n",
        "    save_name=c2s_save_name,\n",
        "    dataset_backend=\"arrow\"\n",
        ")\n",
        "print(csdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f93526",
      "metadata": {
        "id": "f2f93526"
      },
      "source": [
        "# Load a Pretrained Cell2Sentence Model\n",
        "\n",
        "We will start with a C2S model that has already been pretrained on a diverse set of single-cell datasets. This provides a strong foundation of biological knowledge. The `C2S-Scale-Pythia-1b-pt` and newer C2S-Scale models are good general-purpose models to start from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2acb7e97",
      "metadata": {
        "id": "2acb7e97"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"vandijklab/C2S-Scale-Pythia-1b-pt\"\n",
        "save_dir = \"/home/sr2464/scratch/C2S_API_Testing/Cache_Dir/perturbation_tutorial\"\n",
        "save_name = \"perturbation_pythia_1B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d1353e",
      "metadata": {
        "id": "94d1353e"
      },
      "outputs": [],
      "source": [
        "csmodel = cs.CSModel(\n",
        "    model_name_or_path=model_name_or_path,\n",
        "    save_dir=save_dir,\n",
        "    save_name=save_name\n",
        ")\n",
        "print(csmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08006eaf",
      "metadata": {
        "id": "08006eaf"
      },
      "source": [
        "# Finetune for Perturbation Prediction\n",
        "\n",
        "Now, we'll finetune our model on the perturbation prediction task. We'll define our `TrainingArguments` and then call the `finetune()` method, passing in our `csdata` object and the `PerturbationPromptFormatter` instance we created.\n",
        "\n",
        "For this tutorial, we'll run for a small number of steps (`max_steps=500`). For a full finetuning run, you would typically train for several epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a09042d",
      "metadata": {
        "id": "4a09042d"
      },
      "outputs": [],
      "source": [
        "datetimestamp = datetime.now().strftime('%Y-%m-%d-%H_%M_%S')\n",
        "output_dir = os.path.join(csmodel.save_dir, f\"{datetimestamp}_finetune_{task_name}\")\n",
        "print(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6af62c",
      "metadata": {
        "id": "4d6af62c"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e28b043",
      "metadata": {
        "id": "2e28b043"
      },
      "outputs": [],
      "source": [
        "train_args = TrainingArguments(\n",
        "    bf16=True,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=1e-5,\n",
        "    logging_steps=50,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    num_train_epochs=1,\n",
        "    eval_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    output_dir=output_dir,\n",
        "    max_steps=500  # Shortened for tutorial purposes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04071118",
      "metadata": {
        "id": "04071118"
      },
      "outputs": [],
      "source": [
        "csmodel.fine_tune(\n",
        "    csdata=csdata,\n",
        "    task=task_name,\n",
        "    train_args=train_args,\n",
        "    loss_on_response_only=True, # We only want to calculate loss on the predicted sentence\n",
        "    top_k_genes=200,  # Use top 200 genes for this example, normally would use full cell sentence (all nonzero expressed genes) if possible\n",
        "    prompt_formatter=prompt_formatter  # Pass in our custom prompt formatter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de08f82",
      "metadata": {
        "id": "7de08f82"
      },
      "source": [
        "# Generate Predictions with the Finetuned Model\n",
        "\n",
        "After finetuning, let's load our new model and use it to predict the response to a perturbation for a cell from our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89474061",
      "metadata": {
        "id": "89474061"
      },
      "outputs": [],
      "source": [
        "final_ckpt_path = os.path.join(output_dir, \"checkpoint-500\")\n",
        "final_ckpt_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d63e84",
      "metadata": {
        "id": "38d63e84"
      },
      "outputs": [],
      "source": [
        "save_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebff900c",
      "metadata": {
        "id": "ebff900c"
      },
      "outputs": [],
      "source": [
        "# Load the finetuned model (it's automatically saved to csmodel.model_name_or_path)\n",
        "finetuned_model = cs.CSModel(\n",
        "    model_name_or_path=final_ckpt_path, # Path is updated after finetuning\n",
        "    save_dir=save_dir,\n",
        "    save_name=\"perturbation_predictor_finetuned_final\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca22f14f",
      "metadata": {
        "id": "ca22f14f"
      },
      "outputs": [],
      "source": [
        "finetuned_model.save_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf85b83c",
      "metadata": {
        "id": "cf85b83c"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c36e4b1",
      "metadata": {
        "id": "7c36e4b1"
      },
      "outputs": [],
      "source": [
        "final_model = AutoModelForCausalLM.from_pretrained(\n",
        "    finetuned_model.save_path,\n",
        "    cache_dir=os.path.join(csmodel.save_dir, \".cache\"),\n",
        "    trust_remote_code=True\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c828d229",
      "metadata": {
        "id": "c828d229"
      },
      "outputs": [],
      "source": [
        "# Load dataset split done in finetune() function, saved to output directory\n",
        "with open(os.path.join(output_dir, 'data_split_indices_dict.pkl'), 'rb') as f:\n",
        "    data_split_indices_dict = pickle.load(f)\n",
        "\n",
        "data_split_indices_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a9c647",
      "metadata": {
        "id": "54a9c647"
      },
      "outputs": [],
      "source": [
        "# Print a few indices of test samples\n",
        "data_split_indices_dict['test'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a54bcda",
      "metadata": {
        "id": "6a54bcda"
      },
      "outputs": [],
      "source": [
        "# Select a few unseen samples\n",
        "formatted_test_ds = formatted_ds.select(data_split_indices_dict['test'][:10])\n",
        "formatted_test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1feda129",
      "metadata": {
        "id": "1feda129"
      },
      "outputs": [],
      "source": [
        "# Select a sample from the test set for inference\n",
        "sample_idx = 0\n",
        "inference_prompt = formatted_test_ds[sample_idx]['model_input']\n",
        "ground_truth_response = formatted_test_ds[sample_idx]['response']\n",
        "\n",
        "print(\"--- Inference Prompt ---\")\n",
        "print(inference_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d8dd95",
      "metadata": {
        "id": "96d8dd95"
      },
      "outputs": [],
      "source": [
        "# Generate the prediction\n",
        "predicted_response = finetuned_model.generate_from_prompt(\n",
        "    model=final_model,\n",
        "    prompt=inference_prompt,\n",
        "    max_num_tokens=800 # max number of tokens to generate, ~4 tokens per gene\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c807b03c",
      "metadata": {
        "id": "c807b03c"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Ground Truth Perturbed Cell ---\")\n",
        "print(ground_truth_response)\n",
        "print(\"\\n--- Predicted Perturbed Cell ---\")\n",
        "print(predicted_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce20628b",
      "metadata": {
        "id": "ce20628b"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this tutorial, you learned how to finetune a Cell2Sentence model for a custom task: perturbation response prediction. By creating a `PerturbationPromptFormatter`, we were able to structure our data into control-perturbation-response triplets, enabling the model to learn the complex transcriptional changes that occur upon perturbation.\n",
        "\n",
        "This approach is highly flexible and can be adapted to various experimental designs. The finetuned model can now be used for in-silico experiments, such as virtual screening of genetic perturbations or predicting the effect of new compounds, significantly accelerating the pace of biological discovery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1296f4",
      "metadata": {
        "id": "2f1296f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cell2sentence2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}